{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome to AWorld\u2019s Documentation!","text":""},{"location":"#quickstart","title":"Quickstart","text":"<p>Install</p> <p>Agent Construction</p> <p>Workflow Construction</p> <p>Multi-agent System Construction</p> <p>Agent Training</p>"},{"location":"Quickstart/agent_construction/","title":"Building and Running Agents","text":"<p>In AWorld's design, both Workflows and Multi-Agent Systems (MAS) are complex systems built around Agents as the core component. Using the most common llm_agent as an example, this tutorial provides detailed guidance on:</p> <ol> <li>How to quickly build an Agent</li> <li>How to customize an Agent    This document is divided into two parts to explain AWorld's design philosophy.</li> </ol>"},{"location":"Quickstart/agent_construction/#part-1-quick-agent-setup","title":"Part 1: Quick Agent Setup","text":""},{"location":"Quickstart/agent_construction/#declaring-an-agent","title":"Declaring an Agent","text":"<pre><code>from aworld.agents.llm_agent import Agent\n\n# Assign a name to your agent\nagent = Agent(name=\"my_agent\")\n</code></pre>"},{"location":"Quickstart/agent_construction/#configuring-llm","title":"Configuring LLM","text":""},{"location":"Quickstart/agent_construction/#method-1-using-environment-variables","title":"Method 1: Using Environment Variables","text":"<pre><code>import os\n\n## Set up LLM service using environment variables\nos.environ[\"LLM_PROVIDER\"] = \"openai\"  # Choose from: openai, anthropic, azure_openai\nos.environ[\"LLM_MODEL_NAME\"] = \"gpt-4\"\nos.environ[\"LLM_API_KEY\"] = \"your-api-key\"\nos.environ[\"LLM_BASE_URL\"] = \"https://api.openai.com/v1\"  # Optional for OpenAI\n</code></pre>"},{"location":"Quickstart/agent_construction/#method-2-using-agentconfig","title":"Method 2: Using AgentConfig","text":"<pre><code>import os\nfrom aworld.agents.llm_agent import Agent\nfrom aworld.config.conf import AgentConfig\n\nagent_config = AgentConfig(\n    llm_provider=os.getenv(\"LLM_PROVIDER\", \"openai\"),\n    llm_model_name=os.getenv(\"LLM_MODEL_NAME\"),\n    llm_base_url=os.getenv(\"LLM_BASE_URL\"),\n    llm_api_key=os.getenv(\"LLM_API_KEY\"),\n)\n\nagent = Agent(name=\"my_agent\", conf=agent_config)\n</code></pre>"},{"location":"Quickstart/agent_construction/#method-3-using-shared-modelconfig","title":"Method 3: Using Shared ModelConfig","text":"<p>When multiple agents use the same LLM service, you can specify a shared ModelConfig:</p> <pre><code>import os\nfrom aworld.agents.llm_agent import Agent\nfrom aworld.config.conf import AgentConfig, ModelConfig\n\n# Create a shared model configuration\nmodel_config = ModelConfig(\n    llm_provider=os.getenv(\"LLM_PROVIDER\", \"openai\"),\n    llm_model_name=os.getenv(\"LLM_MODEL_NAME\"),\n    llm_base_url=os.getenv(\"LLM_BASE_URL\"),\n    llm_api_key=os.getenv(\"LLM_API_KEY\"),\n)\n\n# Use the shared model config in agent configuration\nagent_config = AgentConfig(\n    llm_config=model_config,\n)\n\nagent = Agent(name=\"my_agent\", conf=agent_config)\n</code></pre>"},{"location":"Quickstart/agent_construction/#configuring-prompts","title":"Configuring Prompts","text":"<pre><code>from aworld.agents.llm_agent import Agent\nimport os\nfrom aworld.config.conf import AgentConfig, ModelConfig\n\nmodel_config = ModelConfig(\n    llm_provider=os.getenv(\"LLM_PROVIDER\", \"openai\"),\n    llm_model_name=os.getenv(\"LLM_MODEL_NAME\"),\n    llm_base_url=os.getenv(\"LLM_BASE_URL\"),\n    llm_api_key=os.getenv(\"LLM_API_KEY\"),\n)\n\nagent_config = AgentConfig(\n    llm_config=model_config,\n)\n\n# Define your system prompt\nsystem_prompt = \"\"\"You are a helpful AI assistant that can assist users with various tasks.\nYou should be polite, accurate, and provide clear explanations.\"\"\"\n\nagent = Agent(\n    name=\"my_agent\",\n    conf=agent_config,\n    system_prompt=system_prompt\n)\n</code></pre>"},{"location":"Quickstart/agent_construction/#configuring-tools","title":"Configuring Tools","text":""},{"location":"Quickstart/agent_construction/#local-tools","title":"Local Tools","text":"<pre><code>from aworld.agents.llm_agent import Agent\nimport os\nfrom aworld.config.conf import AgentConfig, ModelConfig\nfrom aworld.core.tool.func_to_tool import be_tool\n\nmodel_config = ModelConfig(\n    llm_provider=os.getenv(\"LLM_PROVIDER\", \"openai\"),\n    llm_model_name=os.getenv(\"LLM_MODEL_NAME\"),\n    llm_base_url=os.getenv(\"LLM_BASE_URL\"),\n    llm_api_key=os.getenv(\"LLM_API_KEY\"),\n)\n\nagent_config = AgentConfig(\n    llm_config=model_config,\n)\n\nsystem_prompt = \"\"\"You are a helpful agent with access to various tools.\"\"\"\n\n\n# Define a local tool using the @be_tool decorator\n\n@be_tool(tool_name='greeting_tool', tool_desc=\"A simple greeting tool that returns a hello message\")\ndef greeting_tool() -&gt; str:\n    return \"Hello, world!\"\n\n\nagent = Agent(\n    name=\"my_agent\",\n    conf=agent_config,\n    system_prompt=system_prompt,\n    tool_names=['greeting_tool']\n)\n</code></pre>"},{"location":"Quickstart/agent_construction/#mcp-model-context-protocol-tools","title":"MCP (Model Context Protocol) Tools","text":"<pre><code>from aworld.agents.llm_agent import Agent\nimport os\nfrom aworld.config.conf import AgentConfig, ModelConfig\n\nmodel_config = ModelConfig(\n    llm_provider=os.getenv(\"LLM_PROVIDER\", \"openai\"),\n    llm_model_name=os.getenv(\"LLM_MODEL_NAME\"),\n    llm_base_url=os.getenv(\"LLM_BASE_URL\"),\n    llm_api_key=os.getenv(\"LLM_API_KEY\"),\n)\n\nagent_config = AgentConfig(\n    llm_config=model_config,\n)\n\nsystem_prompt = \"\"\"You are a helpful agent with access to file system operations.\"\"\"\n\n# Configure MCP servers\n\nmcp_config = {\n    \"mcpServers\": {\n        \"GorillaFileSystem\": {\n            \"type\": \"stdio\",\n            \"command\": \"python\",\n            \"args\": [\"examples/BFCL/mcp_tools/gorilla_file_system.py\"],\n        },\n    }\n}\n\nagent = Agent(\n    name=\"my_agent\",\n    conf=agent_config,\n    system_prompt=system_prompt,\n    mcp_servers=list(mcp_config.get(\"mcpServers\", {}).keys()),\n    mcp_config=mcp_config\n)\n</code></pre>"},{"location":"Quickstart/agent_construction/#agent-as-tool","title":"Agent as Tool","text":"<pre><code>from aworld.agents.llm_agent import Agent\nimport os\nfrom aworld.config.conf import AgentConfig, ModelConfig\n\nmodel_config = ModelConfig(\n    llm_provider=os.getenv(\"LLM_PROVIDER\", \"openai\"),\n    llm_model_name=os.getenv(\"LLM_MODEL_NAME\"),\n    llm_base_url=os.getenv(\"LLM_BASE_URL\"),\n    llm_api_key=os.getenv(\"LLM_API_KEY\"),\n)\n\nagent_config = AgentConfig(\n    llm_config=model_config,\n)\n\nsystem_prompt = \"\"\"You are a helpful agent that can delegate tasks to other specialized agents.\"\"\"\n\n# Create a specialized tool agent\ntool_agent = Agent(name=\"tool_agent\", conf=agent_config)\n\n# Create the main agent that can use the tool agent\nagent = Agent(\n    name=\"my_agent\",\n    conf=agent_config,\n    system_prompt=system_prompt,\n    agent_names=['tool_agent']\n)\n</code></pre>"},{"location":"Quickstart/agent_construction/#part-2-customizing-agents","title":"Part 2: Customizing Agents","text":""},{"location":"Quickstart/agent_construction/#customizing-agent-input","title":"Customizing Agent Input","text":"<p>Override the <code>init_observation()</code> function to customize how your agent processes initial observations:</p> <pre><code>async def init_observation(self, observation: Observation) -&gt; Observation:\n    # You can add extended information from other agents or third-party storage\n    # For example, enrich the observation with additional context\n    observation.metadata = {\"timestamp\": time.time(), \"source\": \"custom\"}\n    return observation\n</code></pre>"},{"location":"Quickstart/agent_construction/#customizing-model-input","title":"Customizing Model Input","text":"<p>Override the <code>async_messages_transform()</code> function to customize how messages are transformed before being sent to the model:</p> <pre><code>async def async_messages_transform(self,\n                                   image_urls: List[str] = None,\n                                   observation: Observation = None,\n                                   message: Message = None,\n                                   **kwargs) -&gt; List[Dict[str, Any]]:\n    \"\"\"\n    Transform input data into the format expected by the LLM.\n\n    Args:\n         image_urls: List of images encoded using base64\n         observation: Observation from the environment\n         message: Event received by the Agent\n    \"\"\"\n    messages = []\n\n    # Add system context\n    if hasattr(self, 'system_prompt'):\n        messages.append({\"role\": \"system\", \"content\": self.system_prompt})\n\n    # Add user message\n    if message and message.content:\n        messages.append({\"role\": \"user\", \"content\": message.content})\n\n    # Add images if present\n    if image_urls:\n        for img_url in image_urls:\n            messages.append({\n                \"role\": \"user\",\n                \"content\": [{\"type\": \"image_url\", \"image_url\": {\"url\": img_url}}]\n            })\n\n    return messages\n</code></pre>"},{"location":"Quickstart/agent_construction/#customizing-model-logic","title":"Customizing Model Logic","text":"<p>Override the <code>invoke_model()</code> function to implement custom model logic:</p> <pre><code>async def invoke_model(self,\n                       messages: List[Dict[str, str]] = [],\n                       message: Message = None,\n                       **kwargs) -&gt; ModelResponse:\n    \"\"\"Custom model invocation logic.\n       You can use neural networks, rule-based systems, or any other business logic.\n    \"\"\"\n\n      # Example: Use a custom model or business logic\n      if self.use_custom_logic:\n          # Your custom logic here\n          response_content = self.custom_model.predict(messages)\n      else:\n          # Use the default LLM\n          response_content = await self.llm_client.chat_completion(messages)\n\n      return ModelResponse(\n          id=f\"response_{int(time.time())}\",\n          model=self.model_name,\n          content=response_content,\n          tool_calls=None  # Set if tool calls are present\n      )\n</code></pre>"},{"location":"Quickstart/agent_construction/#customizing-model-output","title":"Customizing Model Output","text":"<p>Create a custom <code>ModelOutputParser</code> class and specify it using the <code>model_output_parser</code> parameter:</p> <pre><code>from aworld.models.model_output_parser import ModelOutputParser\n\n\nclass CustomOutputParser(ModelOutputParser[ModelResponse, AgentResult]):\n    async def parse(self, resp: ModelResponse, **kwargs) -&gt; AgentResult:\n        \"\"\"Custom parsing logic based on your model's API response format.\"\"\"\n\n         # Extract relevant information from the model response\n         content = resp.content\n         tool_calls = resp.tool_calls\n\n         # Create your custom AgentResult\n         result = AgentResult(\n             content=content,\n             tool_calls=tool_calls,\n             metadata={\"parsed_at\": time.time()}\n         )\n\n         return result\n\n# Use the custom parser\n\nagent = Agent(\n    name=\"my_agent\",\n    conf=agent_config,\n    model_output_parser=CustomOutputParser()\n)\n</code></pre>"},{"location":"Quickstart/agent_construction/#customizing-agent-response","title":"Customizing Agent Response","text":"<p>Override the <code>async_post_run()</code> function to customize how your agent responds:</p> <pre><code>from aworld.core.message import Message\n\nclass CustomMessage(Message):\n      def __init__(self, content: str, custom_field: str = None):\n            super().__init__(content=content)\n            self.custom_field = custom_field\n\nasync def async_post_run(self,\n                        policy_result: List[ActionModel],\n                        policy_input: Observation,\n                        message: Message = None) -&gt; Message:\n      \"\"\"\n      Customize the agent's response after processing.\n      \"\"\"\n\n      # Process the policy result and create a custom response\n      response_content = f\"Processed {len(policy_result)} actions\"\n      custom_field = \"custom_value\"\n\n       return CustomMessage(\n           content=response_content,\n           custom_field=custom_field\n       )\n</code></pre>"},{"location":"Quickstart/agent_construction/#custom-response-parsing","title":"Custom Response Parsing","text":"<p>If the framework doesn't support your response structure, you can create a custom response parser:</p> <pre><code>from aworld.runners import HandlerFactory\nfrom aworld.runners.default_handler import DefaultHandler\n\n# Define a custom handler name\ncustom_name = \"custom_handler\"\n\n\n@HandlerFactory.register(name=custom_name)\nclass CustomHandler(DefaultHandler):\n    def is_valid_message(self, message: Message):\n        \"\"\"Check if this handler should process the message.\"\"\"\n        return message.category == custom_name\n\n\nasync def _do_handle(self, message: Message) -&gt; AsyncGenerator[Message, None]:\n    \"\"\"Custom message processing logic.\"\"\"\n    if not self.is_valid_message(message):\n        return\n\n    # Implement your custom message processing logic here\n    processed_message = self.process_custom_message(message)\n    yield processed_message\n\n\n# Use the custom handler\nagent = Agent(\n    name=\"my_agent\",\n    conf=agent_config,\n    event_handler_name=custom_name\n)\n</code></pre> <p>Important Note: The <code>custom_name</code> variable value must remain consistent across your handler registration and agent configuration.</p>"},{"location":"Quickstart/agent_training/","title":"AWorld Train","text":"<p>AWorld Training bridges AWorld Agents with external training frameworks (e.g., Reinforcement Learning libraries). It is framework-agnostic, enabling you to bring AWorld Agents or Swarms into your preferred training environment.  To implement agent evolution in AWorld train, five modules need to be considered:</p> <ol> <li>Agent construction (<code>agent</code>): Build the core logic, strategies, and decision-making capabilities of the agent.</li> <li>Tool Environment Settings (<code>env</code>): Build (optional) and configure the tool environment used by the agent,    define the state/action space and interaction mechanism with the agent.</li> <li>Prepare dataset (<code>dataset</code>): The dataset required for Agent training.</li> <li>Reward function (<code>reward</code>): Evaluate the performance of the agent and return a reward.</li> <li>**Training Execution (<code>trainer</code>): ** Training related configurations and training frameworks used.</li> </ol> <p>3, 4, 5 belongs to the adaptation integration module, which is related to the compatibility with specific training frameworks such as Verl. AWorld train has provided support for VeRL and AReaL, making it more convenient for users to use.</p>"},{"location":"Quickstart/agent_training/#building-a-custom-agent","title":"Building a Custom Agent","text":"<p>Use AWorld's agent building capabilities to create agents.</p> <pre><code>import os\nfrom aworld.agents.llm_agent import Agent\nfrom aworld.config import AgentConfig\n\nmcp_config = {\n    \"mcpServers\": {\n        \"gaia_server\": {\n            \"type\": \"streamable-http\",\n            \"url\": \"https://playground.aworldagents.com/environments/mcp\",\n            \"timeout\": 600,\n            \"sse_read_timeout\": 600,\n            \"headers\": {\n                \"ENV_CODE\": \"gaia\",\n                \"Authorization\": f'Bearer {os.environ.get(\"INVITATION_CODE\", \"\")}',\n            }\n        }\n    }\n}\n\nagent_config = AgentConfig(\n    llm_provider=\"verl\",\n    top_k=80\n)\nagent = Agent(\n    name=\"gaia_agent\",\n    desc=\"gaia_agent\",\n    system_prompt=\"Gaia agent system prompt\",\n    mcp_config=mcp_config,\n    mcp_servers=[\"gaia_server\"],\n    conf=agent_config\n)\n</code></pre> <ul> <li>Agent Construction: For details on building single-agent or multi-agent systems, please refer to the Building   and Running an Agent and Building and   Running a Multi-Agent System   guides.</li> <li>MCP Tools: If your agent requires MCP tools, you must configure the corresponding <code>mcp_config</code> file. Instructions   can be found in the Building and Running an Agent guide.</li> </ul>"},{"location":"Quickstart/agent_training/#start-up-training","title":"Start-up Training","text":"<p>AWorld train is a one-click coding pattern that generally requires four items: agent, dataset, reward function, and custom training configuration.</p> <p>Note: Environment variables are independently configured and it is recommended to write them in the <code>.env</code> file.</p> <p>Gaia Training Startup Code</p> <p>Simple example\uff1a</p> <pre><code>from train.trainer.agent_trainer import AgentTrainer\n\n# \u5b9a\u4e49\u6570\u636e\u96c6\ntrain_dataset, test_dataset = \"None or string or code reference\"\n# \u5b9a\u4e49agent\nagent = ...\n# \u5b9a\u4e49\u8bad\u7ec3\u914d\u7f6e\ncustom_train_config = \"string or json\"\n# \u5b9a\u4e49reward\nreward_func = \"None or string or code reference\"\n# \u6784\u5efatrainer\u5b9e\u4f8b\u5e76\u542f\u52a8\u8bad\u7ec3\ntrainer = AgentTrainer(agent=agent,\n                       config=custom_train_config,\n                       reward_func=reward_func,\n                       train_dataset=train_dataset,\n                       test_dataset=test_dataset)\ntrainer.train()\n</code></pre>"},{"location":"Quickstart/agent_training/#dataset","title":"Dataset","text":"<p>A dataset used for training intelligent agents. It can be used as a file path or a Huggingface Dateset instance (generally secondary processing is required) as a parameter and provided to the trainer.</p>"},{"location":"Quickstart/agent_training/#reward-function","title":"Reward Function","text":"<p>Define or adjust reward functions for evaluating agent behavior based on specific task objectives. Taking training gaia as an example, the following code implements the <code>reward function</code> logic required by gaia, code: gaia_reward_function.py</p> <p>Note: The Reward function is recommended as a separate file.</p>"},{"location":"Quickstart/agent_training/#custom-training-configuration","title":"Custom Training Configuration","text":"<p>YAML format configuration file, used to configure training related parameters based on actual situations, for defining training parameters such as iteration times, learning rate, batch size, etc. Configuration example: rpo_trainer.yaml</p>"},{"location":"Quickstart/agent_training/#supplementary","title":"Supplementary","text":"<p>Please pay special attention to the following core configuration items. When values are empty, AWorld will automatically set them based on the user's trainer:</p> <ul> <li><code>train_files</code>, <code>val_files</code>: Specify the file paths for the training dataset and validation dataset, in <code>data</code>.</li> <li><code>agent_loop_config_path</code>: Specify the configuration file for the custom Agentloop, in <code>actor_rollout_def.rollout.agent</code>.</li> <li><code>reward_fn_file_path</code>: Defines the file path where the reward function is located, in <code>custom_deward_function</code>.</li> <li><code>reward_fn_name</code>: Specifies the name of the reward function to be used, in <code>custom_deward_function</code>.</li> </ul> <p>Refer to the VeRL documentation for detailed parameters.</p>"},{"location":"Quickstart/install/","title":"Installation","text":""},{"location":"Quickstart/install/#aworld-agent","title":"AWorld Agent","text":""},{"location":"Quickstart/install/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11+</li> </ul>"},{"location":"Quickstart/install/#install","title":"Install","text":"<pre><code>git clone https://github.com/inclusionAI/AWorld &amp;&amp; cd AWorld\n\npip install .\n</code></pre>"},{"location":"Quickstart/install/#aworld-env","title":"AWorld Env","text":"<p>TODO</p>"},{"location":"Quickstart/install/#aworld-train","title":"AWorld Train","text":"<p>TODO</p>"},{"location":"Quickstart/multi-agent_system_construction/","title":"Building and Running Multi-Agent Systems (MAS)","text":"<p>In the AWorld framework, similar to Workflow Construction, the fundamental building block for MAS is the Agent. By introducing the Swarm concept, users can easily, quickly, and efficiently build complex Multi-Agent Systems. In summary:</p> <ol> <li>Workflow in AWorld: Static, pre-defined execution flows</li> <li>MAS in AWorld: Dynamic, real-time decision-making execution flows</li> </ol> <p>This design ensures unified underlying capabilities (i.e., Agent, Graph-based Topology) while maintaining extensibility.</p> <p>MAS uses event mechanism as the communication basis, where the output from the previous agent serves as the input for the next agent.</p>"},{"location":"Quickstart/multi-agent_system_construction/#quick-mas-construction","title":"Quick MAS Construction","text":"<p>Similar to Workflows, we can easily define communication networks between Agents through topology. The key difference is that by using <code>build_type=GraphBuildType.HANDOFF</code>, we allow dynamic decision-making for inter-agent calling relationships:</p> <ol> <li><code>agent1</code> can selectively decide to call <code>agent2</code> and <code>agent3</code>; the number of calls is also dynamic (once or multiple    times)</li> <li><code>agent2</code> can selectively decide to call <code>agent3</code>; the number of calls is also dynamic (once or multiple times)</li> </ol> <pre><code>from aworld.config.conf import AgentConfig\nfrom aworld.agents.llm_agent import Agent\nfrom aworld.core.agent.swarm import Swarm, GraphBuildType\nfrom aworld.runner import Runners\n\n# Configure agents\nagent_conf = AgentConfig(...)\nagent1 = Agent(name=\"agent1\", conf=agent_conf)\nagent2 = Agent(name=\"agent2\", conf=agent_conf)\nagent3 = Agent(name=\"agent3\", conf=agent_conf)\n\n# Create swarm with dynamic handoff topology\nswarm = Swarm(\n    topology=[(agent1, agent2), (agent2, agent3), (agent1, agent3)],\n    build_type=GraphBuildType.HANDOFF\n)\n\n# Run the swarm\nRunners.run(input=\"your question\", swarm=swarm)\n</code></pre>"},{"location":"Quickstart/multi-agent_system_construction/#specifying-entry-agent","title":"Specifying Entry Agent","text":"<p>Since MAS is essentially a Graph by definition, different Agents can accept external input. We can specify which Agent receives the query using the <code>root_agent</code> parameter.</p> <pre><code>swarm = Swarm(\n    topology=[(agent1, agent2), (agent2, agent3), (agent1, agent3)],\n    build_type=GraphBuildType.HANDOFF,\n    root_agent=[agent1]\n)\n</code></pre>"},{"location":"Quickstart/multi-agent_system_construction/#actions-group-parallel","title":"Actions Group Parallel","text":"<p>The agent's policy may have multiple actions on a decision, including local tools, MCP tools, and agents. AWorld will merge these actions of the same type and automatically parallelize them. The results of parallel execution will be automatically merged and returned to the agent.</p> <p>If you have a custom policy for mixing different types of actions (tools, agents) in parallel, <code>GroupMessage</code> events can be used in <code>async_post_run()</code> or <code>post_run()</code> of <code>Agent</code>.</p> <pre><code>import uuid\nfrom aworld.core.event.base import GroupMessage, TopicType, Message\n\n\ndef async_post_run(self,\n                   policy_result,\n                   policy_input,\n                   message) -&gt; Message:\n    your_actions = [tool1_action1, tool1_action2, agent1, agent2, tool2_action]\n    group_id = f\"agent_id_{uuid.uuid1().hex}\"\n\n    # The setting of other parameters can refer to the implementation of the Agent\n    return GroupMessage(payload=your_actions,\n                        caller=...,\n                        sender=...,\n                        session_id=...,\n                        group_id=group_id,\n                        topic=TopicType.GROUP_ACTIONS,\n                        headers=...)\n\n\n</code></pre>"},{"location":"Quickstart/multi-agent_system_construction/#dynamic-routing","title":"Dynamic Routing","text":"<p>When the <code>async_policy()</code> or <code>policy()</code> function decides which agent to call next, for special cases, Agents may need customized routing based on specific business rules. You can override the handler in the corresponding Agent:</p> <pre><code># Handler name consistency must be maintained\nagent = Agent(..., event_handler_name=\"your_handler_name\")\n</code></pre> <pre><code>from aworld.runners import HandlerFactory\nfrom aworld.runners.handler import DefaultHandler\nfrom aworld.core.event.base import Message, ToolMessage, AgentMessage\nfrom typing import AsyncGenerator\n\n\n@HandlerFactory.register(name=\"your_handler_name\")\nclass YourHandler(DefaultHandler):\n    def is_valid_message(self, message: Message) -&gt; bool:\n        return message.category == \"your_handler_name\"\n\n    async def _do_handle(self, message: Message) -&gt; AsyncGenerator[Message, None]:\n        if not self.is_valid_message(message):\n            return\n\n        # The type of data is generally ActionModel, but can be customized\n        data = message.payload[0]\n        content = data.policy_info\n\n        if \"use_tool1\" in content:\n            # not tool call, but want to use tools\n            yield ToolMessage(\n                payload=...,\n                caller=...,\n                sender=...,\n                receiver=\"tool1\",\n                session_id=...,\n                headers=...\n            )\n        elif \"use_agent1\" in data:\n            # want to use agent as next step\n            yield AgentMessage(\n                payload=...,\n                caller=...,\n                sender=...,\n                receiver=\"agent1\",\n                session_id=...,\n                headers=...\n            )\n        else:\n            ...\n</code></pre> <p>You can refer to the implementation of <code>DefaultTaskHandler</code> in AWorld.</p>"},{"location":"Quickstart/multi-agent_system_construction/#two-examples-of-overriding-routing-react-and-plan-execute","title":"Two Examples of Overriding Routing: ReAct and Plan-Execute","text":""},{"location":"Quickstart/multi-agent_system_construction/#react","title":"ReAct","text":"<pre><code>@HandlerFactory.register(name='react')\nclass ReactHandler(AgentHandler):\n    def is_valid_message(self, message: Message):\n        if message.category != 'react':\n            return False\n        return True\n\n    async def _do_handle(self, message: Message) -&gt; AsyncGenerator[Message, None]:\n        yield message\n</code></pre>"},{"location":"Quickstart/multi-agent_system_construction/#plan-execute","title":"Plan-Execute","text":"<p>Compared to ReAct, agent2 and agent3 can execute in parallel simultaneously.</p> <pre><code>from aworld.core.common import Observation\nfrom aworld.core.event.base import AgentMessage\nfrom aworld.logs.util import logger\n\n\n@HandlerFactory.register(name='plan_execute')\nclass PlanExecuteHandler(AgentHandler):\n    def is_valid_message(self, message: Message):\n        if message.category != 'plan_execute':\n            return False\n        return True\n\n    async def _do_handle(self, message: Message) -&gt; AsyncGenerator[Message, None]:\n        logger.info(f\"PlanExecuteHandler|handle|taskid={self.task_id}|is_sub_task={message.context._task.is_sub_task}\")\n        content = message.payload\n\n        # Parse model plan\n        plan = parse_plan(content[0].policy_info)\n        logger.info(f\"PlanExecuteHandler|plan|{plan}\")\n\n        # Execute steps\n        output, context = execution_steps(plan.steps)\n\n        # Send event message, notify the next processing agent\n        new_plan_input = Observation(content=output)\n        yield AgentMessage(\n            session_id=message.session_id,\n            payload=new_plan_input,\n            sender=self.name(),\n            receiver=self.swarm.communicate_agent.id(),\n            headers={'context': context}\n        )\n</code></pre> <p>For more details, refer to the examples.</p>"},{"location":"Quickstart/multi-agent_system_construction/#combination-and-recursion-of-mas-and-workflow","title":"Combination and Recursion of MAS and Workflow","text":"<p>Same or different types of Swarms can be deeply nested, providing multi-level Swarms with different interaction mechanisms to support complex multi-agent interactions. For example, when creating a travel itinerary planner, using a combination of Workflow + MAS, where Workflow provides deterministic processes and MAS handles multi-source information retrieval and integration.</p> <pre><code>from aworld.config.conf import AgentConfig\nfrom aworld.agents.llm_agent import Agent\nfrom aworld.core.agent.swarm import Swarm, GraphBuildType\n\n# Configure agents\nagent_conf = AgentConfig(...)\n\n# Create five agents\nrewrite = Agent(name=\"rewrite\", conf=agent_conf)\nplan = Agent(name=\"plan\", conf=agent_conf)\nsearch = Agent(name=\"search\", conf=agent_conf)\nsummary = Agent(name=\"summary\", conf=agent_conf)\nreport = Agent(name=\"report\", conf=agent_conf)\n\n# Construct a MAS\nmas = Swarm(\n    topology=[(plan, search), (plan, summary)],\n    build_type=GraphBuildType.HANDOFF,\n    root_agent=[plan]\n)\n\n# Construct a combination of a workflow with the MAS team\ncombination = Swarm(\n    topology=[(rewrite, mas), (mas, report)],\n    root_agent=[rewrite]\n)\n</code></pre>"},{"location":"Quickstart/workflow_construction/","title":"Workflow Construction","text":"<p>We use the classic graph syntax to describe workflows in AWorld.  The following are the basic scenarios for constructing agent workflows.</p>"},{"location":"Quickstart/workflow_construction/#agent-native-workflow","title":"Agent Native Workflow","text":""},{"location":"Quickstart/workflow_construction/#sequential","title":"Sequential","text":"<pre><code>\"\"\"\nSequential Agent Pipeline: agent1 \u2192 agent2 \u2192 agent3\n\nExecutes agents in sequence where each agent's output becomes \nthe next agent's input, enabling multi-step collaborative processing.\n\"\"\"\n\nswarm = Swarm(topology=[(agent1, agent2), (agent2, agent3)], root_agent=[agent1])\nresult: TaskResponse = Runners.run(input=question, swarm=swarm)\n</code></pre>"},{"location":"Quickstart/workflow_construction/#parallel","title":"Parallel","text":"<pre><code>\"\"\"\nParallel Agent Execution with Barrier Synchronization\n\n    Input \u2500\u2500\u252c\u2500\u2192 agent1 \u2500\u2500\u2510\n            \u2502            \u251c\u2500\u2500\u2192 agent3 (barrier wait)\n            \u2514\u2500\u2192 agent2 \u2500\u2500\u2518\n\n- agent1 and agent2 execute in parallel\n- agent3 acts as a barrier, waiting for both agents\n- agent3 processes combined outputs from agent1 and agent2\n\"\"\"\n\nswarm = Swarm(topology=[(agent1, agent3), (agent2, agent3)], root_agent=[agent1, agent2])\nresult: TaskResponse = Runners.run(input=question, swarm=swarm)\n</code></pre>"},{"location":"Quickstart/workflow_construction/#parallel-multi-path","title":"Parallel Multi-Path","text":"<pre><code>\"\"\"\nParallel Multi-Path Agent Execution\n\n    Input \u2500\u2500\u2192 agent1 \u2500\u2500\u252c\u2500\u2500\u2192 agent2 \u2500\u2500\u2510\n                       \u2502             \u2502\n                       \u2514\u2500\u2500\u2192 agent3 \u2190\u2500\u2518 (barrier wait for agent1 &amp; agent2)\n\n- Single input enters only through agent1\n- agent1 distributes to both agent2 and agent3\n- agent2 processes and feeds agent3\n- agent3 waits for both agent1 and agent2 completion\n- agent3 synthesizes outputs from both agent1 and agent2\n\"\"\"\n\nswarm = Swarm(topology=[(agent1, agent2), (agent1, agent3), (agent2, agent3)], root_agent=[agent1])\nresult: TaskResponse = Runners.run(input=question, swarm=swarm)\n</code></pre>"},{"location":"Quickstart/workflow_construction/#task-native-workflow","title":"Task Native Workflow","text":"<p>Task native workflow is further implemented for Isolating the agent runtimes and environments,  in the distributed or other easy-to-overlap scenarios.  Task native workflow is further implemented for isolating agent runtimes and environments,  particularly useful in distributed or other scenarios where tool-isolation is required. </p> <pre><code>task1 = Task(input=\"my question\", agent=agent1)\ntask2 = Task(agent=agent2)\ntask3 = Task(agent=agent3)\ntasks = [task1, task2, task3]\n\nresult: Dict[str, TaskResponse] = Runners.run_task(tasks, RunConfig(sequence_dependent=True))\n</code></pre>"}]}